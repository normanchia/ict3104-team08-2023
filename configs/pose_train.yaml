pretrained_model_path: "/content/FollowYourPose/checkpoints/stable-diffusion-v1-4"
output_dir: "/content/output_model/"

train_data:
    video_path: "/content/FollowYourPose/followyourpose/data/part_1/video_clips/"

    # the prompt is not used
    # prompt:
    #     - "A Iron man on the beach"
    prompt: "None"
    n_sample_frames: 12
    width: 256
    height: 256
    sample_start_idx: 0
    sample_frame_rate: 4
    dataset_set: "train"

validation_data:
    prompts:
        - "A Iron man on the beach"
        - "A Spider man on the snow"
        # - "A Superman on the street"
        # - "A boy on the forest"
    video_length: 4
    width: 256
    height: 256
    num_inference_steps: 25
    guidance_scale: 12.5
    use_inv_latent: False
    num_inv_steps: 50
    dataset_set: "val"

learning_rate: 3e-5
train_batch_size: 1
max_train_steps: 5
checkpointing_steps: 1000 # checkpoints trigger every 1000 steps, meaning creating a saved model
validation_steps: 10
trainable_modules:
    - "attn1.to_q"
    - "attn2.to_q"
    - "attn_temp"
    - "conv_temporal"

# this is what they use for validation
# validation is the inference they do when you do training
skeleton_path: "./generated_skeleton/"

seed: 33
mixed_precision: "no"
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True
